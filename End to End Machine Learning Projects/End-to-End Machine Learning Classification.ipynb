{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51df3f12",
   "metadata": {},
   "source": [
    "## Classification of MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c1c50",
   "metadata": {},
   "source": [
    "We'll take the same approach as before. \n",
    "1. Problem statement.\n",
    "2. Performance measure.\n",
    "3. Get the data.\n",
    "4. Discover and visualize the data to gain insights.\n",
    "5. Prepare the data for Machine Learning algorithms.\n",
    "6. Select a model and train it.\n",
    "7. Fine-tune your model.\n",
    "8. Present your solution.\n",
    "9. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0415e",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "We will perform classification task on MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US census Bureau. This set has been studied so much that it often called the \"Hello World\" of machine learning world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d26d7d",
   "metadata": {},
   "source": [
    "## Performance Measure\n",
    "\n",
    "There are various performance measure we can take. Such as Precision, Recall, Accuracy, Cross Validation Score, ROC-AUC Curve, Confusion Matrix and many more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcd7dd",
   "metadata": {},
   "source": [
    "## Obtaining The Data\n",
    "\n",
    "The data has been collected from Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36c404e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in d:\\anaconda\\lib\\site-packages (from tensorflow-datasets) (3.19.1)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: toml in d:\\anaconda\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from tensorflow-datasets) (1.21.5)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from tensorflow-datasets) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-datasets) (2.27.1)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Collecting etils[epath]\n",
      "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.9)\n",
      "Requirement already satisfied: zipp in d:\\anaconda\\lib\\site-packages (from etils[epath]->tensorflow-datasets) (3.7.0)\n",
      "Collecting importlib_resources\n",
      "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: typing_extensions in d:\\anaconda\\lib\\site-packages (from etils[epath]->tensorflow-datasets) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->tensorflow-datasets) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Building wheels for collected packages: promise, termcolor\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=50a588f8ee15c7a585359b25fc7d8ccf52f5c78356a5b5baf46c145ae197227c\n",
      "  Stored in directory: c:\\users\\souritra\\appdata\\local\\pip\\cache\\wheels\\e1\\e8\\83\\ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=0266997b00fc8a0f93ad21634917c9f820f1f336d7a851b94725b21f98d58183\n",
      "  Stored in directory: c:\\users\\souritra\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built promise termcolor\n",
      "Installing collected packages: etils, importlib-resources, absl-py, termcolor, tensorflow-metadata, promise, dill, tensorflow-datasets\n",
      "Successfully installed absl-py-1.2.0 dill-0.3.5.1 etils-0.6.0 importlib-resources-5.9.0 promise-2.3 tensorflow-datasets-4.6.0 tensorflow-metadata-1.9.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e198542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.base import clone,BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c700ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\",version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1ddc59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72edd5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d7875f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 70000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093ccaa",
   "metadata": {},
   "source": [
    "There are 70,000 images and each image has 784 features. This is because each image has 28 x 28 pixels and each picture simply represents one pixel's intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d185e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
